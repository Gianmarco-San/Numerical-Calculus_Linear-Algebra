{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAvS-CtMogHK"
   },
   "source": [
    "# MD2SL - Master in Data Science and Statistical Learning\n",
    "\n",
    "**Numerical Calculus and Linear Algebra**\n",
    "\n",
    "Exercises 02: Linear systems: LU decomposition and partial pivoting\n",
    "\n",
    "Deadline: 31/03/2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "BXVusMheyD_D"
   },
   "outputs": [],
   "source": [
    "# Installing packages\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import *\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urnzqWnVxtpB"
   },
   "source": [
    "# Exercise 1\n",
    "Let $n\\in\\mathbb{N}$ and $\\widehat{\\mathbf{x}} = \\pmatrix{1.1 \\\\ \\vdots \\\\ 1.1}\\in\\mathbb{R}^n$.\n",
    "\n",
    "1. Consider the matrix $A = (a_{ij})\\in\\mathbb{R}^{n\\times n}$, so that\n",
    "\\begin{equation}\n",
    "  a_{ij} = \\cos(j\\theta),\\ \\text{with}\\ \\theta = \\frac{(2i+1)\\pi}{2n}\n",
    "\\end{equation}\n",
    "\n",
    "  and the linear system $A\\cdot\\mathbf{x} = \\mathbf{b}$, with $\\mathbf{b} = A\\cdot\\widehat{\\mathbf{x}}$.\n",
    "\n",
    "  For $n=5,10,15,20,25,30$, solve the system using the functions `solveLU(A,b)` if possible, otherwise use `solveLUP(A,b)`.\n",
    "  Print the following values, depending on $n$\n",
    "  -  conditioning of the matrix\n",
    "  -  euclidean norm of the relative error\n",
    "  -  euclidean norm of the residual error\n",
    "\n",
    "  and comment the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHUFLCntA6IH"
   },
   "source": [
    "Exercise 01 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Yd7W-VAkzFYa"
   },
   "outputs": [],
   "source": [
    "# Matrix A\n",
    "def get_matrix_ex1(n):\n",
    "    \n",
    "    # TO DO\n",
    "    A = np.zeros((n, n), dtype = float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        for j in range(n):\n",
    "            \n",
    "            A[i,j] = float(math.cos(float(j) * (math.pi * (1. + 2. * float(i))) / (2. * float(n))))\n",
    "            \n",
    "    return A\n",
    "\n",
    "# A = get_matrix_ex1(int(10))\n",
    "# print(A)    \n",
    "\n",
    "\n",
    "def upperTriangular(A,b):\n",
    "    \n",
    "    # A: upper triangular coefficient matrix\n",
    "    # b: vector of costant terms\n",
    "    \n",
    "    x = b.copy()\n",
    "\n",
    "    for j in range(A.shape[1]-1, -1, -1):  # n-2:-1:0\n",
    "        \n",
    "        x[j] = x[j]/A[j,j]\n",
    "        \n",
    "        for i in range(j):\n",
    "            \n",
    "            x[i] = x[i] - A[i,j] * x[j]\n",
    "            \n",
    "    return x\n",
    "\n",
    "\n",
    "def gaussLU(A):\n",
    "    \n",
    "    #Get the number of rows\n",
    "    n = A.shape[0]\n",
    "    LU = A.copy()\n",
    "    \n",
    "    #Loop over rows\n",
    "    for k in range(n-1):\n",
    "        \n",
    "        if LU[k,k] == 0:\n",
    "            \n",
    "            raise ValueError('A has no lu decomposition.')\n",
    "            \n",
    "        LU[k+1:,k]     = LU[k+1:,k]/LU[k,k] # calcolo moltiplicatori\n",
    "        \n",
    "        LU[k+1:,k+1:] = LU[k+1:,k+1:]- np.outer(LU[k+1:,k],LU[k,k+1:]) # outer vector product\n",
    "    \n",
    "    return LU\n",
    "\n",
    "\n",
    "def lowerTriangularUnitDiagonal(A,b):\n",
    "    \n",
    "    assert A.shape[0] == A.shape[1]  # m == n, otherwise break\n",
    "    \n",
    "    x = b.copy()\n",
    "    \n",
    "    for j in range(A.shape[1]):\n",
    "        \n",
    "        for i in range(j+1, A.shape[1]):\n",
    "            \n",
    "            x[i] = x[i]-A[i,j]*x[j]\n",
    "            \n",
    "    return x\n",
    "\n",
    "\n",
    "def solveLU(LU, b):\n",
    "    \n",
    "    assert LU.shape[0] == LU.shape[1]  # m == n, otherwise break\n",
    "    \n",
    "    n = LU.shape[0]\n",
    "    \n",
    "    assert b.shape[0] == n             # b length == n according to LU, otherwise break\n",
    "    \n",
    "    x = lowerTriangularUnitDiagonal(LU,b)\n",
    "    x = upperTriangular(LU,x)\n",
    "    \n",
    "    rnorm = np.linalg.norm(b-(np.eye(n) + np.tril(LU,-1)) @ np.triu(LU) @ x, 2) # matrix multiplication with @ \n",
    "    \n",
    "    return x, rnorm\n",
    "\n",
    "\n",
    "def gaussLUP(A):\n",
    "    \n",
    "    LU = A.copy()\n",
    "    n = LU.shape[0]\n",
    "    piv = np.arange(0,n)\n",
    "    \n",
    "    for k in range(n-1):\n",
    "        \n",
    "        # pivoting\n",
    "        r_idx = np.argmax(abs(LU[k:,k])) + k\n",
    "        \n",
    "        if LU[r_idx,k]==0:\n",
    "            raise ValueError('Singular matrix.')\n",
    "        \n",
    "        piv[[k,r_idx]] = piv[[r_idx,k]]\n",
    "        LU[[k,r_idx]] = LU[[r_idx,k]]\n",
    "        \n",
    "        # LU \n",
    "        LU[k+1:,k]     = LU[k+1:,k]/LU[k,k]\n",
    "        LU[k+1:,k+1:] = LU[k+1:,k+1:]- np.outer(LU[k+1:,k],LU[k,k+1:])  # outer vector product\n",
    "        \n",
    "    return LU, piv\n",
    "\n",
    "\n",
    "def solveLUP(LU,b,P):\n",
    "    \n",
    "    bp = b[P]  # otherwise also b is changed\n",
    "    x, rnorm = solveLU(LU,bp)\n",
    "    \n",
    "    return x, rnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ASUpYonN1AQK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "n      cd       res     res-pivot      err     err-pivot\n",
      "--------------------------------------------------------\n",
      " 5  1.41e+00  2.33e-15   8.60e-16   3.38e-16   2.21e-16\n",
      "10  1.41e+00  1.55e-12   2.82e-15   1.28e-13   5.49e-16\n",
      "15  1.41e+00  4.11e-10   6.77e-15   6.64e-11   3.97e-16\n",
      "20  1.41e+00  5.71e-07   1.87e-14   1.23e-08   9.14e-16\n",
      "25  1.41e+00  1.66e-04   2.02e-14   5.23e-06   9.05e-16\n",
      "30  1.41e+00  2.04e-02   1.65e-14   1.14e-03   7.33e-16\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------------------------------------------')\n",
    "print('n      cd       res     res-pivot      err     err-pivot')\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "\n",
    "for n in range(5, 35, 5): # range(start, stop, step) -> [5, 10, 15, 20, 25, 30]\n",
    "    \n",
    "    A = get_matrix_ex1(n)\n",
    "    \n",
    "    # exact solution of the system\n",
    "    x_hat = np.array(n * [1.1])\n",
    "    \n",
    "    # known vector\n",
    "    b = A @ x_hat\n",
    "    \n",
    "    LU       = gaussLU(A)\n",
    "    x, rnorm = solveLU(LU, b)\n",
    "    err_r    = np.linalg.norm(x - x_hat) / np.linalg.norm(x)  # relative error\n",
    "\n",
    "    LU_piv, P        = gaussLUP(A)\n",
    "    x_piv, rnorm_piv = solveLUP(LU_piv, b, P)\n",
    "    err_r_piv        = np.linalg.norm(x_piv - x_hat) / np.linalg.norm(x_piv)  # retive error\n",
    "    \n",
    "    print(f'{n:2}  {np.linalg.cond(A):.2e}  {rnorm:.2e}   {rnorm_piv:.2e}   {err_r:.2e}   {err_r_piv:.2e}')\n",
    "    \n",
    "print('--------------------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQI7160lx1hr"
   },
   "source": [
    "- What happens to the condition number of $A$? What does it mean?\n",
    "\n",
    "The conditional number is steady. This means that the conditioning of the problem doesn't change with the dimension of the matrix A. \n",
    "\n",
    "Moreover, 1.41 is a good condition number, so the matrix is well-conditioned.\n",
    "\n",
    "  \n",
    "- How do the naive and pivot residuals behave?\n",
    "\n",
    "The naive residuals grow rapidly (in the order of 10^2รท3 every 5n)  with the increasing of n. \n",
    "\n",
    "Similarly, the pivot residuals grow but at a slower pace than before.\n",
    "\n",
    "  \n",
    "- How do the naive and pivot relative errors behave?\n",
    "\n",
    "The naive relative errors grow fast, while the pivot errors are pretty steady and small.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Please, note that some outcomes in Jupyter where displayed differently than in Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtLOzNMSxy5U"
   },
   "source": [
    "# Exercise 2\n",
    "Let $n\\in\\mathbb{N}$ and $\\widehat{\\mathbf{x}} = \\pmatrix{1.1 \\\\ \\vdots \\\\ 1.1}\\in\\mathbb{R}^n$.\n",
    "\n",
    "1. Consider the matrix $A = (a_{ij})\\in\\mathbb{R}^{n\\times n}$, so that\n",
    "\\begin{equation}\n",
    "  a_{ij} = (i+1)^{j}\n",
    "\\end{equation}\n",
    "\n",
    "  and the linear system $A\\cdot\\mathbf{x} = \\mathbf{b}$, with $\\mathbf{b} = A\\cdot\\widehat{\\mathbf{x}}$.\n",
    "\n",
    "  For $n=1,\\dots,10$, solve the system using the functions `solveLU(A,b)` if possible, otherwise use `solveLUP(A,b)`.\n",
    "  Print following values, depending on $n$\n",
    "  -  conditioning of the matrix\n",
    "  -  euclidean norm of the relative error\n",
    "  -  euclidean norm of the residual error\n",
    "\n",
    "  and comment the results.\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQTqlv08A_mO"
   },
   "source": [
    "Exercise 02 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "DZSvG3oWBCEb"
   },
   "outputs": [],
   "source": [
    "def get_matrix_ex2(n):\n",
    "    # TO DO\n",
    "    A = np.zeros((n, n), dtype = int)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        for j in range(n):\n",
    "            \n",
    "            A[i,j] = (i + 1) ** j\n",
    "            \n",
    "    return A\n",
    "\n",
    "# A = get_matrix_ex2(10)\n",
    "# print(A)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "InzBn4ieCQig"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "n     cd        res     res-pivot     err     err-pivot\n",
      "-------------------------------------------------------\n",
      " 1  1.00e+00  0.00e+00   0.00e+00   0.00e+00   0.00e+00\n",
      " 2  6.85e+00  0.00e+00   0.00e+00   0.00e+00   0.00e+00\n",
      " 3  7.09e+01  0.00e+00   0.00e+00   8.72e-16   7.00e-01\n",
      " 4  1.17e+03  0.00e+00   7.11e-15   7.96e-15   9.57e-01\n",
      " 5  2.62e+04  1.30e-13   2.27e-13   5.21e-14   9.99e-01\n",
      " 6  7.31e+05  9.39e-13   9.39e-13   4.85e-12   1.00e+00\n",
      " 7  2.45e+07  8.19e-12   3.26e-11   1.50e-10   1.00e+00\n",
      " 8  9.52e+08  9.33e-10   1.17e-10   1.16e-09   1.00e+00\n",
      " 9  4.23e+10  3.84e-09   7.51e-09   2.28e-08   1.00e+00\n",
      "10  2.11e+12  5.96e-08   6.74e-08   2.44e-06   1.00e+00\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------------------------------------')\n",
    "print('n     cd        res     res-pivot     err     err-pivot')\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "for n in range(1, 11): # range(start, stop, step) -> [5, 10, 15, 20, 25, 30]\n",
    "    \n",
    "    A = get_matrix_ex2(n)\n",
    "    \n",
    "    # exact solution of the system\n",
    "    x_hat = np.array(n * [1.1])\n",
    "    \n",
    "    # known vector\n",
    "    b = A @ x_hat\n",
    "    \n",
    "    LU       = gaussLU(A)\n",
    "    x, rnorm = solveLU(LU, b)\n",
    "    err_r    = np.linalg.norm(x - x_hat) / np.linalg.norm(x)  # relative error\n",
    "\n",
    "    LU_piv, P        = gaussLUP(A)\n",
    "    x_piv, rnorm_piv = solveLUP(LU_piv, b, P)\n",
    "    err_r_piv        = np.linalg.norm(x_piv - x_hat) / np.linalg.norm(x_piv)  # retive error\n",
    "    \n",
    "    print(f'{n:2}  {np.linalg.cond(A):.2e}  {rnorm:.2e}   {rnorm_piv:.2e}   {err_r:.2e}   {err_r_piv:.2e}')\n",
    "\n",
    "print('--------------------------------------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9jpNfoGEdK2"
   },
   "source": [
    "- What happens to the condition number of $A$? What does it mean?\n",
    "\n",
    "Differently than the previous case, in this problem the conditional number of A grows with n, reaching high values, so the matrix is ill-conditioned.\n",
    "\n",
    "- How do the naive and pivot residuals behave?\n",
    "\n",
    "The naive residuals grow rapidly with n, starting from n = 5.\n",
    "\n",
    "Similarly, the pivot residuals grow but faster than before, starting from n = 4.\n",
    "\n",
    "- How do the naive and pivot relative errors behave\n",
    "\n",
    "The naive relative errors is zero until n = 3, when it starts to grow.\n",
    "\n",
    "While the pivot errors are pretty steady.\n",
    "\n",
    "---\n",
    "\n",
    "Please, note that some outcomes in Jupyter where displayed differently than in Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2-RN9cRx3Qf"
   },
   "source": [
    "# Exercise 3\n",
    "Let $A\\in\\mathbb{R}^{n\\times n}$ a tridiagonal matrix\n",
    "\\begin{equation}\n",
    "  A = \\pmatrix{d_0     & a_0    &        &         & \\huge 0 \\\\\n",
    "               c_1     & \\ddots & \\ddots &         &         \\\\\n",
    "                       & \\ddots & \\ddots & \\ddots  &         \\\\\n",
    "                       &        & \\ddots & \\ddots  & a_{n-2} \\\\\n",
    "               \\huge 0 &        &        & c_{n-1} & d_{n-1} \\\\}\n",
    "\\end{equation}\n",
    "\n",
    "for which its LU decomposition exists. Hence, $A = L\\cdot U$ with\n",
    "\\begin{equation}\n",
    "L = \\pmatrix{1       &        &         & \\huge0 \\\\\n",
    "             l_1     & \\ddots &         &        \\\\\n",
    "                     & \\ddots & \\ddots  &        \\\\\n",
    "             \\huge 0 &        & l_{n-1} & 1},\n",
    "\\quad\n",
    "U = \\pmatrix{u_0       &  a_0   &         & \\huge0 \\\\\n",
    "                     & \\ddots & \\ddots  &        \\\\\n",
    "                     &        & \\ddots  & a_{n-2}\\\\\n",
    "             \\huge 0 &        &         & u_{n-1}}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Example given for $n=4$.\n",
    "\\begin{equation}\n",
    "\\pmatrix{d_0 & a_0 & 0   & 0   \\\\\n",
    "         c_1 & d_1 & a_1 & 0   \\\\\n",
    "         0   & c_2 & d_2 & a_2 \\\\\n",
    "         0   & 0   & c_3 & d_3} = \\pmatrix{1   & 0   & 0   & 0 \\\\\n",
    "                                           l_2 & 1   & 0   & 0 \\\\\n",
    "                                           0   & l_3 & 1   & 0 \\\\\n",
    "                                           0   & 0   & l_4 & 1 }\\pmatrix{u_0   & a_0 & 0   & 0   \\\\\n",
    " 0     & u_1 & a_1 & 0   \\\\\n",
    " 0     & 0   & u_2 & a_2 \\\\\n",
    " 0     & 0   & 0   & u_3  }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "In particular,\n",
    "\\begin{array}{clll}\n",
    "          & c_1 = l_1u_0        &  c_2 = l_2u_1       & c_3 = l_3u_2\\\\\n",
    "d_0 = u_0 & d_1 = l_1a_0 + u_1  &  d_2 = l_2a_1 + u_2 & d_3 = l_3a_2 + u_3.\\\\\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "\n",
    "1. Write a python function `thomas(c,d,a)` which takes in input the diagonals   of a tridiagonal square matrix $A\\in\\mathbb{R}^{n\\times n}$\n",
    "  - $c:$  lower diagonal\n",
    "  - $d:$  main diagonal\n",
    "  - $a:$  upper diagonal\n",
    "  \n",
    "  and returns the diagonals of the lu decomposition $A = L\\cdot U$\n",
    "  - $l:$  lower diagonal of $L$\n",
    "  - $u:$  upper diagonal of $U$ \n",
    "\n",
    "  by implementing the following *Thomas algorithm*.\n",
    "\n",
    "  **Input:** $c$, $d$, $a$\n",
    "  1. $u_0$ = $d_0$\n",
    "  2. for $i=1,\\dots,n-1$ \n",
    "    - $l_i$ = $c_i / u_{i-1}$\n",
    "    - $u_i$ = $d_i - l_ia_{i-1}$\n",
    "  **Output:** $l$, $u$\n",
    "\n",
    "2. Test the function `thomas(c, d, a)` on the following tridiagonal matrices.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "(a)\\ \\pmatrix{1 & 4 & 0 & 0\\\\\n",
    "             3 & 4 & 1 & 0\\\\\n",
    "             0 & 2 & 3 & 4\\\\\n",
    "             0 & 0 & 1 & 3}\n",
    "             \\\\\n",
    "             \\\\\n",
    "(b)\\ \\pmatrix{2  & 1  & 0  & 0\\\\\n",
    "             -1 & 2  & 1  & 0\\\\\n",
    "             0  & -1 & 2  & 1\\\\\n",
    "             0  & 0  & -1 & 2 \n",
    "            }\n",
    "            \\\\\n",
    "            \\\\\n",
    "(c)\\ \\pmatrix{ 2 &  1 &  0 &  0 &  0 & 0\\\\\n",
    "              -1 &  4 &  1 &  0 &  0 & 0\\\\\n",
    "               0 & -1 &  4 &  1 &  0 & 0\\\\\n",
    "               0 &  0 & -1 &  4 &  1 & 0\\\\\n",
    "               0 &  0 &  0 & -1 &  4 & 1\\\\\n",
    "               0 &  0 &  0 &  0 & -1 & 2}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "  - reconstruct the $L$ and $U$ matricies of their LU decomposition;\n",
    "  - compute the recontruction error as $\\texttt{norm}(A - L\\cdot U)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOWbstqHYgfi"
   },
   "source": [
    "Exercise 3.1 - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "1UZu219JoRhO"
   },
   "outputs": [],
   "source": [
    "def thomas(c, d, a):\n",
    "    \n",
    "    # TO DO\n",
    "    n = len(d)\n",
    "    u = np.zeros(n)\n",
    "    l = np.zeros(n - 1)\n",
    "    u[0] = d[0]\n",
    "    \n",
    "    for i in range(n - 1):\n",
    "        \n",
    "        l[i] = c[i] / u[i]\n",
    "        \n",
    "        u[i+1] = d[i+1] - l[i] * a[i]\n",
    "        \n",
    "    return l, u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scn1yL057FJJ"
   },
   "source": [
    "Exercise 3.1.a - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwvKQrHraGg5",
    "outputId": "c1d29fe3-7ae3-42e7-ba4f-0610b7d44574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.0\n",
      "\n",
      "[[1. 4. 0. 0.]\n",
      " [3. 4. 1. 0.]\n",
      " [0. 2. 3. 4.]\n",
      " [0. 0. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# fill in\n",
    "A =  np.array([[1, 4, 0, 0],\n",
    "               [3, 4, 1, 0],\n",
    "               [0, 2, 3, 4],\n",
    "               [0, 0, 1, 3]])\n",
    "\n",
    "d = np.diag(A)      # main diagonal of A\n",
    "c = np.diag(A, -1)  # lower diagonal of A\n",
    "a = np.diag(A, +1)  # upper diagonal of A\n",
    "\n",
    "l, u = thomas(c, d, a)\n",
    "\n",
    "L = np.diag([1] * A.shape[0]) + np.diag(l, -1)  # assemble\n",
    "\n",
    "U = np.diag(u) + np.diag(a, +1)                 # assemble\n",
    "\n",
    "error = np.linalg.norm(A - L @ U)\n",
    "\n",
    "print(f'Reconstruction error: {error}\\n\\n{(L @ U)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul4VlBMu7JJj"
   },
   "source": [
    "Exercise 3.1.b - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "En_JHOHcgXBv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 2.220446049250313e-16\n",
      "\n",
      "[[ 2.  1.  0.  0.]\n",
      " [-1.  2.  1.  0.]\n",
      " [ 0. -1.  2.  1.]\n",
      " [ 0.  0. -1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# fill in\n",
    "A =  np.array([[ 2,  1,  0, 0],\n",
    "               [-1,  2,  1, 0],\n",
    "               [ 0, -1,  2, 1],\n",
    "               [ 0,  0, -1, 2]])\n",
    "\n",
    "d = np.diag(A)      # main diagonal of A\n",
    "c = np.diag(A, -1)  # lower diagonal of A\n",
    "a = np.diag(A, +1)  # upper diagonal of A\n",
    "\n",
    "l, u = thomas(c, d, a)\n",
    "\n",
    "L = np.diag([1] * A.shape[0]) + np.diag(l, -1)  # assemble\n",
    "\n",
    "U = np.diag(u) + np.diag(a, +1)                 # assemble\n",
    "\n",
    "error = np.linalg.norm(A - L @ U)\n",
    "\n",
    "print(f'Reconstruction error: {error}\\n\\n{(L @ U)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfLCM4qQ7LPx"
   },
   "source": [
    "Exercise 3.1.c - Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "i9ljiZGwhtmP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 6.280369834735101e-16\n",
      "\n",
      "[[ 2.  1.  0.  0.  0.  0.]\n",
      " [-1.  4.  1.  0.  0.  0.]\n",
      " [ 0. -1.  4.  1.  0.  0.]\n",
      " [ 0.  0. -1.  4.  1.  0.]\n",
      " [ 0.  0.  0. -1.  4.  1.]\n",
      " [ 0.  0.  0.  0. -1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# fill in\n",
    "A =  np.array([[ 2,  1,  0,  0,  0,  0],\n",
    "               [-1,  4,  1,  0,  0,  0],\n",
    "               [ 0, -1,  4,  1,  0,  0],\n",
    "               [ 0,  0, -1,  4,  1,  0],\n",
    "               [ 0,  0,  0, -1,  4,  1],\n",
    "               [ 0,  0,  0,  0, -1,  2]])\n",
    "\n",
    "d = np.diag(A)      # main diagonal of A\n",
    "c = np.diag(A, -1)  # lower diagonal of A\n",
    "a = np.diag(A, +1)  # upper diagonal of A\n",
    "\n",
    "l, u = thomas(c, d, a)\n",
    "\n",
    "L = np.diag([1] * A.shape[0]) + np.diag(l, -1)  # assemble\n",
    "\n",
    "U = np.diag(u) + np.diag(a, +1)                 # assemble\n",
    "\n",
    "error = np.linalg.norm(A - L @ U)\n",
    "\n",
    "print(f'Reconstruction error: {error}\\n\\n{(L @ U)}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
